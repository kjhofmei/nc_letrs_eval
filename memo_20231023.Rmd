---
title: "RP Memo"
author: "Kenny Hofmeister"
output: html_document
date: "2023-10-23"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width = 10)

library(data.table)
library(stringr)
library(ggplot2)
library(kableExtra)

```

```{r load, include=FALSE}

setwd("~/Documents/Michigan/PUBPOL 712/rp/")

rawdatadir = "./raw_data/"
workdatadir = "./working_data/"
outdir = "./output/"
codedir = "./code/"

district_assessment = fread(paste0(workdatadir, 'prep_district_assessment.csv'))
district_school_counts = fread(paste0(workdatadir, 'prep_district_school_counts.csv'))
district_student_counts = fread(paste0(workdatadir, 'prep_district_student_counts.csv'))
letrs_cohorts = fread(paste0(workdatadir, 'prep_letrs_cohorts.csv'))

```

```{r prep, include=FALSE}

# merge in letrs cohorts
district_student_counts = merge.data.table(district_student_counts,
                                           letrs_cohorts,
                                           by=c('lea_code'),
                                           all.x = TRUE)
district_student_counts[is.na(letrs_cohort) & lea_code == 'CH', letrs_cohort := 0]

district_school_counts = merge.data.table(district_school_counts,
                                           letrs_cohorts,
                                           by=c('lea_code'),
                                           all.x = TRUE)
district_school_counts[is.na(letrs_cohort) & lea_code == 'CH', letrs_cohort := 0]

district_assessment = merge.data.table(district_assessment,
                                           letrs_cohorts,
                                           by=c('lea_code'),
                                           all.x = TRUE)
district_assessment[is.na(letrs_cohort) & lea_code == 'CH', letrs_cohort := 0]

# get weighted means of proficient by year/subject/cohort
stats = district_assessment[!is.na(letrs_cohort), .(mean = weighted.mean(as.numeric(glp_pct), as.numeric(den), na.rm = TRUE)), by=c('letrs_cohort', 'year', 'subject')]

# convert cohort to factor for visualization
stats[, letrs_cohort := factor(letrs_cohort)]

# add missing values for 2020  
stats_2020 = unique(stats[, .(letrs_cohort, subject, year = 2020, mean = NA)])

stats = rbind(stats,
              stats_2020)

# define variables to plot
plot_vars = c('RD03', 'RD04', 'RD05', 'RD06', 'RD07', 'RD08', 'EOG')

counts = district_assessment[!is.na(letrs_cohort), .(count = weighted.mean(as.numeric(glp_pct), as.numeric(den), na.rm = TRUE)), by=c('letrs_cohort', 'year', 'subject')]

```

## Notes

This memo presents some basic descriptive statistics about the three cohorts that make up North Carolina's LETRS training implementation. There are `r nrow(unique(district_assessment[letrs_cohort==1, .(lea_code)]))` districts in the first cohort,
`r nrow(unique(district_assessment[letrs_cohort==2, .(lea_code)]))` districts in the second, and `r nrow(unique(district_assessment[letrs_cohort==3, .(lea_code)]))` in the third. The first cohort began training in fall 2021, the second in winter 2021, and the third in summer 2022. All data are publicly available and were downloaded from the [NCDPI website](https://www.dpi.nc.gov/data-reports).

## Tables

The first table describes the number of schools, overall and by type, for each cohort. E refers to elementary schools (grades PK:05), M to middle schools (06:08), and H to high schools (09:12). Combinations of E, M, H indicate that the school serves students whose grades span the combination (for example, E/M serves grades PK:08). Title I is a proportion of all schools in the cohort.

The second table describes the number of students, total and on average, for each cohort. The first column lists the total number of students enrolled at districts in each cohort. The next two columns list the average number of students per district and per elementary school within each cohort. The last two columns list the median number of students per district and per elementary school. Note that only the average number of elementary school students is reported for each district, so the mean/median represent the average/median of these reported averages. 

A few things stand out:
  
  * Cohort 3 includes nearly twice as many districts but not twice as many elementary schools or students, which suggests that the cohort 3 districts are smaller than cohort 1 and 2 districts
    + The average number of students in a cohort 3 district is smaller than in cohorts 1 and 2, but the median is larger, suggesting that there are a few very large districts in cohorts
      1 and 2
    + Cohort 3 does have slightly higher elementary school enrollment counts, however
  * Cohort 3 has a substantially larger proportion of Title I schools 
  * All cohorts experienced substantial enrollment declines between SY20 and SY21

```{r tab, echo=FALSE}

# prep school counts
district_school_counts_bycohort = district_school_counts[!is.na(letrs_cohort), .(total = sum(school_n, na.rm = TRUE)), by=c('letrs_cohort', 'year', 'category')]
district_school_counts_bycohort[, category := factor(category, levels = c('elementary', 'elem/middle', 'elem/middle/high', 'middle', 'middle/high', 'high', 'title i', 'all'))]
setorder(district_school_counts_bycohort, category)
district_school_counts_bycohort_wide = dcast(district_school_counts_bycohort, letrs_cohort + year ~ category, value.var = 'total')
district_school_counts_bycohort_wide[, `title i` := round(`title i` / all, 2)]
setorder(district_school_counts_bycohort_wide, year, letrs_cohort)

# kable(district_school_counts_bycohort_wide[year %in% c(2018, 2019, 2020, 2021, 2022), -c('year')], 
#       booktabs = TRUE,
#       align = paste0(c('r', rep('c', dim(district_school_counts_bycohort_wide)[2])), collapse = ''),
#       col.names = c('LETRS cohort', 'E', 'E/M', 'E/M/H', 'M', 'M/H', 'H', 'Title I', 'All')) %>% 
#   kable_styling(full_width = F, 
#                 position = 'center') %>%
#   group_rows('2018', 1, 3) %>%
#   group_rows('2019', 4, 6) %>%
#   group_rows('2020', 7, 9) %>%
#   group_rows('2021', 10, 12) %>%
#   group_rows('2022', 13, 15)

kable(district_school_counts_bycohort_wide[year %in% c(2021), -c('year')], 
      booktabs = TRUE,
      align = paste0(c('r', rep('c', dim(district_school_counts_bycohort_wide)[2])), collapse = ''),
      col.names = c('LETRS cohort', 'E', 'E/M', 'E/M/H', 'M', 'M/H', 'H', 'Title I prop.', 'All'),
      caption = 'School counts, SY2020-21') %>% 
  kable_styling(full_width = F, 
                position = 'center')

# prep student counts
district_student_counts_bycohort = district_student_counts[!is.na(letrs_cohort), .(total = sum(avg_student_num),
                                                               mean = round(mean(avg_student_num)),
                                                               median = round(median(avg_student_num))),
                                                           by=c('letrs_cohort', 'year', 'category')]
district_student_counts_bycohort = district_student_counts_bycohort[category %in% c('all', 'elementary') & year %in% seq(2018, 2022)]
district_student_counts_bycohort_wide = dcast(district_student_counts_bycohort, letrs_cohort + year ~ category, value.var = c('total', 'mean', 'median'))
district_student_counts_bycohort_wide[, total_elementary := NULL]
setorder(district_student_counts_bycohort_wide, year, letrs_cohort)

kable(district_student_counts_bycohort_wide[, -c('year')], 
      booktabs = TRUE,
      align = paste0(c('r', rep('c', dim(district_student_counts_bycohort_wide)[2])), collapse = ''),
      col.names = c('LETRS cohort', 'Total, all schools', 'District', 'Elementary', 'District', 'Elementary'),
      caption = 'Student counts') %>% 
  kable_styling(full_width = F, 
                position = 'center') %>%
  group_rows('2018', 1, 4) %>%
  group_rows('2019', 5, 8) %>%
  group_rows('2020', 9, 12) %>%
  group_rows('2021', 13, 16) %>%
  group_rows('2022', 17, 20) %>%
  add_header_above(c(' ' = 2, 'Mean enrl' = 2, 'Median enrl' = 2))

```

## Time series: test scores

The following plots describe the proportion of students who score proficient or above on annual standardized tests. Assessment data are publicly available (via school accountability datasets) starting in 2017-18, and there are no test scores available for the 2019-20 school year. RD03 is the third grade end-of-grade standardized assessment, RD04 is the fourth grade assessment, and so forth. "EOG" is a composite of all end-of-grade standardized tests administered (reading, math, science) at all grades (3-8). To calculate the cohort proportion, I take the mean of each district's proportion, with each district proportion weighted by the total number of students who took each test in the district in a given year.

In terms of selection, relative trends do not suggest a monotonic relationship between student achievement and cohort choice. Cohort 3, the latest cohort, consistently has the lowest proportion of students testing proficient on reading assessments, while cohort 2 (which followed shortly after cohort 1) consistently has the highest proportion. 

It is difficult to assess the parallel trends assumption from these plots: the proficient proportions for RD03 are roughly parallel across cohorts, but this is not the case for RD04. Cohorts 1 and 2 are basically identical on the EOG composite pre-pandemic, but separate after 2019-20. All cohorts see a substantial decline in the proportion of students testing proficient after 2020-19. 

```{r ts, echo=FALSE, warning=FALSE}

for(v in plot_vars) {
  
  p = ggplot(stats[subject == v], aes(x = year, y = mean, group = letrs_cohort, color = letrs_cohort)) +
    geom_line(aes(linetype = letrs_cohort)) + 
    geom_point() +   
    theme_classic() + 
    labs(x = 'School year', 
         y = 'Percent',
         title = paste0(v, ' percent at/above level 3, weighted average within cohort'),
         caption = 'School year 2018 = 2017/18') +
    labs(color  = 'LETRS cohort', linetype = 'LETRS cohort') +
    scale_y_continuous(breaks = seq(35, 75, 5)) +
    coord_cartesian(ylim=c(35,75))

  print(p)
  
}

```


```{r den_check, echo=FALSE}

# district_den_check = district_assessment[!is.na(letrs_cohort) & subject == 'EOG' & year %in% c(2019, 2021, 2022), .(agency_code, year, den)]
# district_den_check_wide = dcast(district_den_check, agency_code ~ year, value.var = 'den')
# district_den_check_wide[, diff_2021_2019 := `2021` - `2019`]
# district_den_check_wide[, diff_2022_2021 := `2022` - `2021`]
# 
# ggplot(district_assessment[!is.na(letrs_cohort) & subject == 'EOG'], aes(x = year, y = den, group = agency_code)) +
#   geom_line() +
#   theme(legend.position="none")
# 
# ggplot(district_den_check_wide, aes(x = diff_2021_2019, y = diff_2022_2021)) +
#   geom_point(alpha = .5)

```

